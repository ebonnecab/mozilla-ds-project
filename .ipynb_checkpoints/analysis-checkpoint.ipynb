{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mozilla 2019 Outreachy Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initial Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages need for exploratory data analysis and data visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll start by using Pandas to convert the CSV file into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks to Pandas built in .head() function, we can preview some of the columns from our dataset. However, this is just a sneak peak. \n",
    "\n",
    "I want to know more about each column and their datatypes. With this information, I can decide which data analysis methods are best suited for this dataset and whether some data cleaning is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check column names\n",
    "col_names = df.columns\n",
    "print(list(col_names))\n",
    "\n",
    "#get datatypes for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This dataset has a mix of datatypes including floats, integers, and objects (which represent strings).**\n",
    "\n",
    "_sidenote:_\n",
    "From the information above, we can see certain features have very little data to offer. For example, there are only seven properties mentioned have pools therefore we can go ahead and probably assume the PoolQC feature won't be the best choice for describing the Sales Price. Three other features with few data are MiscFeature, Alley, and Fence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I've decided to drop the features with too few values since they won't be the best source of information.\n",
    "\n",
    "I'm using pandas .drop() function to access these specific columns and drop them while still keeping the same number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PoolQC', 'Alley', 'Fence', 'MiscFeature'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am using some basic built-in Pandas functions to assess the cleanliness of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy thing to check for is whether or not the dataframe has any duplicate rows due to some error when the data was being compiled. Using pandas .duplicated() function, I created a temporary dataframe where all duplicates would be stored. It returned an empty dataframe, meaning there are no duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for duplicate rows (there are none)\n",
    "duplicatesdf = df[df.duplicated()]\n",
    "print(duplicatesdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to look out for when exploring your dataset is NaN or missing values. You wanna drop or fill NaN values so they don't cause errors or skew your data when you begin your analysis. Another handy built in pandas function is .isna() which will check if column has any null values and reutrns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any columns contain nan values\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to know more about the columns with NaN values so I used .sum() to get the total number for each column. Next, I'm going to consult the data_description file to get an understanding of those particular columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine nan values closer\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakdown of columns with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LotFrontage = linear feet of street connected to property. (These NaN values could be due to properties with no lot frontage as opposed to errors or missing information)\n",
    "- MasVnrType, MasVnrArea = Homes that have mason veneers and the area in square feet. (These NaN values represent properties that don't have mason veneers, it is not due to an error)\n",
    "- BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2 = These columns describe various aspects of the basement in these units. (According to the data description, NA symbolizes the homes without basements. Therefore we know these aren't due to errors)\n",
    "- Electrical = type of electrical system in property. (There is only one NaN value probably due to a small error or missing information\n",
    "- FireplaceQu = quality of fireplace (NaN values can be attributed to homes without a fireplace. This is not due to errors)\n",
    "- GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond = descriptive information about properties with garages (NaN values represent homes with no garages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've concluded that all the NaN values, excluding the Electrical column, are mostly valid and due to some properties having certain features that others don't.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the rest of the values in the LotFrontage column are floats, I am using Pandas .fillna() function to put a 0 in place of NaN to represent properties with no Lot Frontage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'].fillna(0.0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values to confirm that it worked \n",
    "df['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to handle the mason veneer type and the mason veneer area featueres separately since one is a string object and the other is a float. I'm going to replace the type with NoMV (no mason veneer) and the area with the value 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'].fillna('NoMV', inplace = True)\n",
    "df['MasVnrArea'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "df[['MasVnrType', 'MasVnrArea']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for the basement properties are all strings. I've decided to replace NA with NB (no basement) which creates a new class within that category to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['BsmtQual', 'BsmtCond', 'BsmtExposure']].fillna('NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['BsmtFinType1', 'BsmtFinType2']] = df[['BsmtFinType1', 'BsmtFinType2']].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values \n",
    "df[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the one electrical NaN value will be pretty inconsequential to the whole dataset. I'm going to change the value to NotSpecif so it wont throw an error later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].fillna('NotSpecif', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for nan values to see if it worked\n",
    "df['Electrical'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fireplace Quality is another string object. I am going to replace NA with NF (no fireplace) so that there isn't a null value for properties without this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu'].fillna('NF', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that it worked\n",
    "df['FireplaceQu'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I am going to replace the null values in the Garage category with NG to represent properties without garages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']].fillna('NG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GarageCars', 'GarageArea']] = df[['GarageCars', 'GarageArea']].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I've replaced all the null values in the dataframe as part of my data cleaning process. After I confirm it worked by checking the entire dataframe for null values, I can move on to the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column I am going to drop is the ID column. The dataframe has an index and this feature isn't necessary for answering the questions about the sales price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using pandas built-in .describe() function to get some summary statistics about the numerical data presented in the dataframe. There is some interesting information about how many unique values each column has, the top value found, the min and max for each column, and the std deviation to name a few. There are NaN values where certain descriptive statistics don't apply to that datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am going to create a dataframe specifically for numerical datatypes so we can explore the numerical data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include = ['float64', 'int64'])\n",
    "num_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sidenote:_ Now that I've separated the numerical data, I am noticing new features now that I'd like to take a closer look at later such as Overall Quality and Overall Condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution of Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.distplot(df['SalePrice'], kde=False, color='#F85888', bins=100)\n",
    "plt.title('Sale Price', fontsize=16)\n",
    "plt.xlabel('US Dollars', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Plot of Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.kdeplot(df['SalePrice'], color='#fec508', shade=True)\n",
    "plt.title('Sale Price', fontsize=16)\n",
    "plt.xlabel('US Dollars', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=df['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows which rows are outliers using the z score\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "def get_z_score(data):\n",
    "    z = np.abs(stats.zscore(data))\n",
    "    threshold = 3\n",
    "    print(np.where(z > 3))\n",
    "\n",
    "z_score = get_z_score(df['SalePrice'])\n",
    "z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interquartile Range (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['SalePrice'].quantile(0.25)\n",
    "Q3 = df['SalePrice'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Using pandas describe method dataframe summary](https://backtobazics.com/python/pandas-describe-method-dataframe-summary/)\n",
    "- [How to make histogram in python with pandas and seaborn](https://cmdlinetips.com/2019/02/how-to-make-histogram-in-python-with-pandas-and-seaborn/)\n",
    "- [Ways to Detect and Remove Outliers](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
